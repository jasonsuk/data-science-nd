{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Workflow\n",
    "Following the machine learning workflow to build a classifier for corporate messages.\n",
    "\n",
    "Starting with the review of works on 01_clean_tokenize.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jsuk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/jsuk/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build load_data and tokenize function\n",
    "\n",
    "\n",
    "def load_data() :\n",
    "    ''' File path: ./corporate_messaging.csv -- latin-1 encoding\n",
    "        Open the file, clean the data and return the variables \n",
    "        Variable X: text, y: category) '''\n",
    "\n",
    "    df = pd.read_csv('corporate_messaging.csv', encoding='latin-1')\n",
    "    \n",
    "    # 1. Exlcude unmeaningful category 'Exclude'\n",
    "    # 2. Use the data with confidence of 100%\n",
    "    df = df[(df['category'] != 'Exclude') & (df['category:confidence'] == 1)]\n",
    "    \n",
    "    X = df['text']\n",
    "    y = df['category']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "\n",
    "def tokenizer(text) : \n",
    "    '''To be applied to one text at a time inside iteration \n",
    "    or be included in CounterVectorizer method as a parameter\n",
    "    '''\n",
    "    \n",
    "    # Normalization : lowercase, remove punctuation and whitespace\n",
    "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text.lower().strip())\n",
    "    \n",
    "    # Replace url with 'urlplaceholder' string\n",
    "    url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "    \n",
    "    # Tokenize, lemmatize the text\n",
    "    tokens = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    for token in word_tokenize(text) : \n",
    "        if token not in stopwords.words('english') :\n",
    "            tokens.append(lemmatizer.lemmatize(token))\n",
    "    \n",
    "    return tokens\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load data and perform a train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X, y = load_data()\n",
    "\n",
    "# perform train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Train classifier\n",
    "* Fit and transform the training data with `CountVectorizer`. Hint: You can include your tokenize function in the `tokenizer` keyword argument!\n",
    "* Fit and transform these word counts with `TfidfTransformer`.\n",
    "* Fit a classifier to these tfidf values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate transformers and classifier\n",
    "vect = CountVectorizer(tokenizer=tokenizer)\n",
    "tfidf = TfidfTransformer()\n",
    "clf = LogisticRegression() # fit logistic regression first\n",
    "\n",
    "# Fit and/or transform each to the data\n",
    "X_train_counts = vect.fit_transform(X_train)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_counts)\n",
    "clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Predict on test data\n",
    "* Transform (no fitting) the test data with the same CountVectorizer and TfidfTransformer\n",
    "* Predict labels on these tfidf values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test data\n",
    "X_test_counts = vect.transform(X_test)\n",
    "X_test_tfidf = tfidf.transform(X_test_counts)\n",
    "\n",
    "# Predict test labels\n",
    "y_pred = clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Display results\n",
    "Display a confusion matrix and accuracy score based on the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['Action' 'Dialogue' 'Information']\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 80   2   1]\n",
      " [  0  22   0]\n",
      " [ 57  28 603]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Action       0.58      0.96      0.73        83\n",
      "    Dialogue       0.42      1.00      0.59        22\n",
      " Information       1.00      0.88      0.93       688\n",
      "\n",
      "    accuracy                           0.89       793\n",
      "   macro avg       0.67      0.95      0.75       793\n",
      "weighted avg       0.94      0.89      0.90       793\n",
      "\n",
      "\n",
      "Accuracy: 0.8890290037831021\n"
     ]
    }
   ],
   "source": [
    "labels = np.unique(y_pred)\n",
    "confusion_mat = confusion_matrix(y_pred, y_test)\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "\n",
    "print(\"Labels:\", labels, end='\\n\\n')\n",
    "print(\"Confusion Matrix:\\n\", confusion_mat, end='\\n\\n')\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or print out all at once with one line code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Action       0.96      0.58      0.73       137\n",
      "    Dialogue       1.00      0.42      0.59        52\n",
      " Information       0.88      1.00      0.93       604\n",
      "\n",
      "    accuracy                           0.89       793\n",
      "   macro avg       0.95      0.67      0.75       793\n",
      "weighted avg       0.90      0.89      0.88       793\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", clf_report, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Step: Refactor\n",
    "Organize these steps into the following functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(y_test, y_pred) :\n",
    "    clf_report = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\\n\", clf_report, end='\\n\\n')\n",
    "    \n",
    "def main() : \n",
    "    \n",
    "    # Load the data and split train, test set\n",
    "    X, y = load_data()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    \n",
    "    # Instantiate estimators\n",
    "    # TfidfVectorizer combines CountVectorizer and TfidfTransformer\n",
    "    tfidf = TfidfVectorizer(tokenizer=tokenizer)\n",
    "    clf = LogisticRegression() \n",
    "    \n",
    "    # Train the data\n",
    "    X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "    clf.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    # Transform X_test and run prediction\n",
    "    # Be careful not to fit again\n",
    "    X_test_tfidf = tfidf.transform(X_test)\n",
    "    y_pred = clf.predict(X_test_tfidf)\n",
    "    \n",
    "    display_results(y_test, y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      Action       0.93      0.62      0.74       115\n",
      "    Dialogue       1.00      0.40      0.57        40\n",
      " Information       0.87      0.99      0.93       446\n",
      "\n",
      "    accuracy                           0.88       601\n",
      "   macro avg       0.93      0.67      0.75       601\n",
      "weighted avg       0.89      0.88      0.87       601\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run program\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search\n",
    "\n",
    "Grid search can be used to optimize hyper parameters of a model.  All you need to do is create a dictionary of parameters to search, using keys for the names of the parameters and values for the list of parameter values to check. Then, pass the model and parameter grid to the grid search object.\n",
    "\n",
    "Then when you call fit on this grid search object, it will run cross validation on all different combinations of these parameters to find the best combination of parameters for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:\n",
    "\n",
    "    parameters = {\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'C':[1, 10]\n",
    "    }\n",
    "\n",
    "    svc = SVC()\n",
    "    clf = GridSearchCV(svc, parameters)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "<br>\n",
    "\n",
    "Parameters tells Scikit-learn to evaluate 2 x 2 = 4 combinataions of `kernel` and 'C' parameter values. Grid Search has **cv** parameter which refers to #folds for cross validation. If cv=5, there will be 2 x 2 x 5 = 20 rounds of training.\n",
    "\n",
    "Further to [CAUTION for data leakage](#leakage)! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's incorporate grid search into your modeling process. To start, include an import statement for `GridSearchCV` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/jsuk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/jsuk/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/jsuk/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(['punkt', 'wordnet', 'averaged_perceptron_tagger'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "\n",
    "def tokenize(text):\n",
    "    detected_urls = re.findall(url_regex, text)\n",
    "    for url in detected_urls:\n",
    "        text = text.replace(url, \"urlplaceholder\")\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens\n",
    "\n",
    "\n",
    "class StartingVerbExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def starting_verb(self, text):\n",
    "        sentence_list = nltk.sent_tokenize(text)\n",
    "        for sentence in sentence_list:\n",
    "            pos_tags = nltk.pos_tag(tokenize(sentence))\n",
    "            first_word, first_tag = pos_tags[0]\n",
    "            if first_tag in ['VB', 'VBP'] or first_word == 'RT':\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_tagged = pd.Series(X).apply(self.starting_verb)\n",
    "        return pd.DataFrame(X_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View parameters in pipeline\n",
    "Before modifying your build_model method to include grid search, view the parameters in your pipeline here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([\n",
    "        ('nlp_transformer', Pipeline([\n",
    "            ('count_vect', CountVectorizer(tokenizer=tokenize)),\n",
    "            ('tfidf', TfidfTransformer())\n",
    "        ])),\n",
    "        ('starting_verb', StartingVerbExtractor())\n",
    "    ])),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify your `build_model` function to return a GridSearchCV object.\n",
    "Try to grid search some parameters in your data transformation steps as well as those for your classifier! Browse the parameters you can search above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model() : \n",
    "    pipeline = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "            ('transformer', Pipeline([\n",
    "                ('countVect', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('tfidf', TfidfTransformer())\n",
    "                ])),\n",
    "            ('startingVerb', StartingVerbExtractor())\n",
    "        ])),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ])\n",
    "    \n",
    "    # set a dictionary of parameters\n",
    "    paramters = {\n",
    "#         'features__transformer__countVect__ngram_range': ((1, 1), (1,2)),\n",
    "#         'features__transformer__countVect__max_df': (0.75, 0.90, 1),\n",
    "#         'features__transformer__countVect__max_features': (None, 5000, 10000),\n",
    "#         'features__transformer__tfidf__use_idf': (True, False),\n",
    "        'clf__n_estimators': (50, 100, 200),\n",
    "        'features__transformer_weights': (\n",
    "            {'text_pipeline': 1, 'starting_verb': 0.5},\n",
    "            {'text_pipeline': 0.5, 'starting_verb': 1},\n",
    "            {'text_pipeline': 0.8, 'starting_verb': 1},\n",
    "        )            \n",
    "    }\n",
    "\n",
    "    # create grid search object\n",
    "    cv = GridSearchCV(pipeline, param_grid=paramters) # 5 folds as default\n",
    "    \n",
    "    return cv\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run program to test\n",
    "Running grid search can take a while, especially if you are searching over a lot of parameters! If you want to reduce it to a few minutes, try commenting out some of your parameters to grid search over just 1 or 2 parameters with a small number of values each. Once you know that works, feel free to add more parameters and see how well your final model can perform! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels: ['Action' 'Dialogue' 'Information']\n",
      "Confusion Matrix:\n",
      " [[ 79   0  21]\n",
      " [  3  34   7]\n",
      " [  4   0 453]]\n",
      "Accuracy: 0.9417637271214643\n",
      "\n",
      "Best Parameters: {'clf__n_estimators': 50, 'features__transformer_weights': {'text_pipeline': 1, 'starting_verb': 0.5}}\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    df = pd.read_csv('corporate_messaging.csv', encoding='latin-1')\n",
    "    df = df[(df[\"category:confidence\"] == 1) & (df['category'] != 'Exclude')]\n",
    "    X = df.text.values\n",
    "    y = df.category.values\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def display_results(cv, y_test, y_pred):\n",
    "    labels = np.unique(y_pred)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    accuracy = (y_pred == y_test).mean()\n",
    "\n",
    "    print(\"Labels:\", labels)\n",
    "    print(\"Confusion Matrix:\\n\", confusion_mat)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"\\nBest Parameters:\", cv.best_params_)\n",
    "\n",
    "\n",
    "def main():\n",
    "    X, y = load_data()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    model = build_model()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    display_results(model, y_test, y_pred)\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Advantages of using pipeline\n",
    "The entire texts are obtained directly from the course notes. In the above example, without pipeline implementation, I personally would possibly have fallen into mistakes, such as\n",
    "- repeating fit_transform() for the test set, instead of transform() \n",
    "- accidentally skipping vector transformation for the test set\n",
    "\n",
    "By using pipeline, it just requires fitting the estimator for the train sets, and predicting/transforming the result for the test sets, and that is pretty easy and free of mental burden!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Simplicity and Convencience\n",
    "\n",
    "> **Automates repetitive steps** - Chaining all of your steps into one estimator allows you to fit and predict on all steps of your sequence automatically with one call. It handles smaller steps for you, so you can focus on implementing higher level changes swiftly and efficiently.\n",
    "\n",
    "> **Easily understandable workflow** - Not only does this make your code more concise, it also makes your workflow much easier to understand and modify. Without Pipeline, your model can easily turn into messy spaghetti code from all the adjustments and experimentation required to improve your model.\n",
    "\n",
    "> **Reduces mental workload** - Because Pipeline automates the intermediate actions required to execute each step, it reduces the mental burden of having to keep track of all your data transformations. Using Pipeline may require some extra work at the beginning of your modeling process, but it prevents a lot of headaches later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Optimizing Entire Workflow\n",
    "\n",
    "> GRID SEARCH: Method that automates the process of testing different hyper parameters to optimize a model.\n",
    "- By running grid search on your pipeline, you're able to optimize your entire workflow, including data transformation and modeling steps. This accounts for any interactions among the steps that may affect the final metrics.\n",
    "- Without grid search, tuning these parameters can be painfully slow, incomplete, and messy.\n",
    "\n",
    "\n",
    "### 3. Preventing Data leakage <a id=\"leakage\"></a>\n",
    "- Using Pipeline, all transformations for data preparation and feature extractions occur within each fold of the cross validation process.\n",
    "\n",
    "- This prevents common mistakes where you’d allow your training process to be influenced by your test data - for example, if you used the entire training dataset to normalize or extract features from your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example : \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(X_train)\n",
    "\n",
    "    parameters = {\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'C':[1, 10]\n",
    "    }\n",
    "\n",
    "    svc = SVC()\n",
    "    clf = GridSearchCV(svc, parameters)\n",
    "    clf.fit(scaled_data, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This may seem okay at first, but if you standardize your whole training dataset, and then use cross validation in grid search to evaluate your model, you've got data leakage. \n",
    "\n",
    "Grid search uses cross validation to score your model, meaning it splits your training data into folds of train and validation sets, trains your model on the train set, and scores it on the validation set, and does this multiple times.\n",
    "\n",
    "However, each time, or fold, that this happens, the model already has knowledge of the validation set because all the data was rescaled based on the distribution of the whole training dataset. Important factors like the mean and standard deviation are influenced by the whole dataset. This means the model perform better than it really should on unseen data, since information about the validation set is always baked into the rescaled values of your train dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way to fix this, would be to make sure you run standard scaler only on the training set, and not the validation set within each fold of cross validation. Pipelines allow you to do just this.\n",
    "\n",
    "Example: \n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('clf', SVC())\n",
    "    ])\n",
    "\n",
    "    parameters = {\n",
    "        'scaler__with_mean': [True, False]\n",
    "        'clf__kernel': ['linear', 'rbf'],\n",
    "        'clf__C':[1, 10]\n",
    "    }\n",
    "\n",
    "    cv = GridSearchCV(pipeline,\n",
    "    param_grid=parameters)\n",
    "\n",
    "    cv.fit(X_train, y_train)\n",
    "    y_pred = cv.predict(X_test)\n",
    "\n",
    "Now, since the rescaling is included as part of the pipeline, the standardization doesn't happen until we run grid search. Meaning in each fold of cross validation, the rescaling is done only on the data that the model is trained on, preventing leakage from the validation set. As you can see, pipelines are very valuable to removing the risk of data leakage during the data preparation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
